parallel::clusterApply(
cl = cl,
x = .data,
fun = shlrtools::playerLinkScraper
)
## Reads the information on the team page
teamPage <-
rvest::read_html(team)
## Scrapes the roster pages from the team page
teamRoster <-
teamPage %>%
rvest::html_elements("strong a") %>%
.data[
lapply(
.data,
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
) %>%
unlist()
] %>%
rvest::html_attr("href")
playerLinks <-
parallel::clusterApply(
cl,
shlrtools::leagueLinks(),
fun = shlrtools::teamScraper
) %>%
unlist() %>%
parallel::clusterApply(
cl = cl,
x = .,
fun = shlrtools::playerLinkScraper
)
browse()
browser()
playerLinkScraper(team)
playerLinkScraper(team)
teamPage <-
rvest::read_html(team)
teamPage
teamPage %>%
rvest::html_elements("strong a")
teamPage %>%
rvest::html_elements("strong a") %>%
.data[
lapply(
.data,
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
) %>%
unlist()
]
.data = NULL
teamPage %>%
rvest::html_elements("strong a") %>%
.data[
lapply(
.data,
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
) %>%
unlist()
]
## Scrapes the roster pages from the team page
teamRoster <-
teamPage %>%
rvest::html_elements("strong a")
teamRoster[[1]]
teamRoster
sapply(
.data,
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
) %>%
unlist()
teamPage %>%
rvest::html_elements("strong a") %>%
.data[
sapply(
.data,
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
) %>%
unlist()
]
.data
teamPage %>%
rvest::html_elements("strong a") %>%
.data
## Scrapes the roster pages from the team page
teamRoster <-
rvest::html_attr(
rvest::html_elements(teamPage, "strong a")[
sapply(
rvest::html_elements(teamPage, "strong a"),
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
)
]
)
sapply(
rvest::html_elements(teamPage, "strong a"),
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
)
rvest::html_elements(teamPage, "strong a")[
sapply(
rvest::html_elements(teamPage, "strong a"),
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
)
]
## Scrapes the roster pages from the team page
teamRoster <-
rvest::html_attr(
rvest::html_elements(teamPage, "strong a")[
sapply(
rvest::html_elements(teamPage, "strong a"),
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
)
],
"href"
)
## Scrapes the roster pages from the team page
teamRoster <-
rvest::html_attr(
rvest::html_elements(teamPage, "strong a")[
sapply(
rvest::html_elements(teamPage, "strong a"),
FUN = function(x){
x %>%
rvest::html_text2() %>%
stringr::str_detect(pattern = "Roster")
}
)
],
"href"
)
## As some teams have more than 20 players, the second page of the roster is added
## THIS MIGHT PRODUCE DUPLICATES IN CASE TEAMS HAVE LESS PLAYERS
rosterLinks <-
teamRoster %>%
c(
.data,
paste(
.data,
"&page=2",
sep = ""
)
)
## Scrapes all player links from the roster pages
playerLinks <-
lapply(
rosterLinks,
FUN = function(page){
paste(baseLink, page, sep = "") %>%
rvest::read_html() %>%
rvest::html_elements("td.forumdisplay_regular div span a") %>%
rvest::html_attr("href") %>%
.data[
!stringr::str_detect(.data, "&action=newpost") &
!stringr::str_detect(.data, "&action=lastpost") &
!stringr::str_detect(.data, "simulationhockey") &
!stringr::str_detect(.data, "&page=2")
] %>%
stringi::stri_remove_empty_na() %>%
unique()
}
) %>%
unlist() %>%
unique()
## Scrapes all player links from the roster pages
playerLinks <-
lapply(
rosterLinks,
FUN = function(page){
links <-
paste(baseLink, page, sep = "") %>%
rvest::read_html() %>%
rvest::html_elements("td.forumdisplay_regular div span a") %>%
rvest::html_attr("href")
cleanLinks <-
links[
!stringr::str_detect(links, "&action=newpost") &
!stringr::str_detect(links, "&action=lastpost") &
!stringr::str_detect(links, "simulationhockey") &
!stringr::str_detect(links, "&page=2")
] %>%
stringi::stri_remove_empty_na() %>%
unique()
}
) %>%
unlist() %>%
unique()
## Scrapes all player links from the roster pages
playerLinks <-
lapply(
rosterLinks,
FUN = function(page){
links <-
paste(baseLink, page, sep = "") %>%
rvest::read_html() %>%
rvest::html_elements("td.forumdisplay_regular div span a") %>%
rvest::html_attr("href")
cleanLinks <-
links[
!stringr::str_detect(links, "&action=newpost") &
!stringr::str_detect(links, "&action=lastpost") &
!stringr::str_detect(links, "simulationhockey") &
!stringr::str_detect(links, "&page=2")
] %>%
stringi::stri_remove_empty_na() %>%
unique()
}
) %>%
unlist() %>%
unique()
rosterLinks
## As some teams have more than 20 players, the second page of the roster is added
## THIS MIGHT PRODUCE DUPLICATES IN CASE TEAMS HAVE LESS PLAYERS
rosterLinks <-
teamRoster %>%
c(
.data,
paste(
.data,
"&page=2",
sep = ""
)
)
## As some teams have more than 20 players, the second page of the roster is added
## THIS MIGHT PRODUCE DUPLICATES IN CASE TEAMS HAVE LESS PLAYERS
rosterLinks <-
c(
teamRoster,
paste(
teamRoster,
"&page=2",
sep = ""
)
)
## Scrapes all player links from the roster pages
playerLinks <-
lapply(
rosterLinks,
FUN = function(page){
links <-
paste(baseLink, page, sep = "") %>%
rvest::read_html() %>%
rvest::html_elements("td.forumdisplay_regular div span a") %>%
rvest::html_attr("href")
cleanLinks <-
links[
!stringr::str_detect(links, "&action=newpost") &
!stringr::str_detect(links, "&action=lastpost") &
!stringr::str_detect(links, "simulationhockey") &
!stringr::str_detect(links, "&page=2")
] %>%
stringi::stri_remove_empty_na() %>%
unique()
}
) %>%
unlist() %>%
unique()
playerLinks
playerLinks <-
parallel::clusterApply(
cl,
shlrtools::leagueLinks(),
fun = shlrtools::teamScraper
) %>%
unlist() %>%
parallel::clusterApply(
cl = cl,
x = .,
fun = shlrtools::playerLinkScraper
)
library(shlrtools)
playerLinks <-
parallel::clusterApply(
cl,
shlrtools::leagueLinks(),
fun = shlrtools::teamScraper
) %>%
unlist() %>%
parallel::clusterApply(
cl = cl,
x = .,
fun = shlrtools::playerLinkScraper
)
playerLinks <-
parallel::clusterApply(
cl,
shlrtools::leagueLinks(),
fun = shlrtools::teamScraper
) %>%
unlist() %>%
parallel::clusterApply(
cl = cl,
x = .,
fun = shlrtools::playerLinkScraper
)
temp <- scraper()
library(shlrtools)
temp <- scraper()
library(shlrtools)
temp <- scraper()
library(shlrtools)
temp <- scraper()
temp
library(shlrtools)
temp <- scraper()
playerLinks <-
parallel::clusterApply(
cl,
shlrtools::leagueLinks(),
fun = shlrtools::teamScraper
) %>%
unlist() %>%
parallel::clusterApply(
cl = cl,
x = .,
fun = shlrtools::playerLinkScraper
) %>%
unlist() %>%
c(
.,
c(
shlrtools::prospectFALinks()
) %>%
sapply(FUN = shlrtools::prospectsFAScraper) %>%
unlist()
) %>%
unique() %>%
stringi::stri_remove_na()
playerScraper(playerLinks[1])
library(shlrtools)
playerScraper(playerLinks[1])
library(shlrtools)
playerScraper(playerLinks[1])
player = playerLinks[1]
### Takes the player link scraped from the team pages
##  If it is a complete link with the base url there it scrapes it directly
##  For use with teamLinkScraper and playerLinkScraper then only the endings are used, requiring the baseLink addition
if(stringr::str_detect(player, "simulationhockey")){
} else{
baseLink <- "https://simulationhockey.com/"
player <- paste(baseLink, player, sep = "")
}
### Reads the information
topic <- xml2::read_html(player)
topic
###  Reading the player information from topic title
title <-
topic %>%
rvest::html_nodes("title") %>%
rvest::html_text() %>%
stringr::str_split(pattern = " - |- ") %>%
unlist() %>%
stringr::str_squish()
title
if(length(title) == 2){
NAME <-
title %>%
dplyr::nth(2)
CLASS <-
title %>%
stringr::str_extract_all(pattern = "S[0-9]+") %>%
unlist() %>%
dplyr::nth(1)
if(length(CLASS)==0){
CLASS <- "Unspecified"
}
POSITION <-
title %>%
dplyr::nth(1) %>%
stringr::str_split(pattern = "]|\\)") %>%
unlist() %>%
stringr::str_squish() %>%
dplyr::nth(2)
} else if(length(title) == 3){
NAME <-
title %>%
dplyr::nth(3)
CLASS <-
title %>%
stringr::str_extract_all(pattern = "S[0-9]+") %>%
unlist() %>%
dplyr::nth(1)
if(length(CLASS)==0){
CLASS <- "Unspecified"
}
POSITION <-
title %>%
dplyr::nth(2)
} else {
## If something is wrong with the title splits, return NA for each of these.
NAME <- NA
CLASS <- NA
POSITION <- NA
}
### Checks if the name includes a nickname
if(NAME %>% is.na()){
#Do nothing
NICKNAME <- NA
} else if (NAME %>% stringr::str_detect(pattern = "\"")){
NICKNAME <-
NAME %>%
stringr::str_extract_all(pattern = "\"[A-z ]+\"", simplify = TRUE)
NAME <-
NAME %>%
stringr::str_remove_all(pattern = "\"[A-z ]+\"") %>%
stringr::str_squish()
} else {
NICKNAME <- NA
}
### Reading the TPE from the post title
TPE <-
topic %>%
rvest::html_nodes("small") %>%
dplyr::nth(1) %>%
rvest::html_text() %>%
stringr::str_extract_all(pattern = "[0-9]+") %>%
unlist() %>%
as.numeric()
TPE
if(length(TPE) == 0){
TPE = NA
}
## Specifies the user defined tags that will be removed from the user name
userTags <-
paste0(
"SHL Commissioner|SHL GM|SHL HO|Co-Commissioner|Commissioner|",
"SMJHL Intern|SMJHL GM|SMJHL HO|SMJHL Commissioner|",
"IIHF Commissioner|IIHF Federation Head|WJC Commissioner|",
"SMJHL All-Star Committee|SHL All-Star Committee|HOF Committee|",
"SMJHL Awards Committee|SHL Awards Committee|Awards Committee|",
"Rookie Mentor Committee|Appeals Committee|All-Star Committee|",
"Registered|Rookie|Historian|Recruitment Team|Deep Dives Head|",
paste(teamInfo$team, collapse = "|"),"|","Team [A-z ]+|",
"Head Office|Coach|Budget Director|Graphic Graders|Moderators|",
"Player Updaters|PGS Grader|Player Progression Director|",
"Fantasy League Manager|Simmer|Head Updater|Deep Dive Head|",
"Owner|Media Graders|Bank Manager|Mentor|",
"Site Management|Trading Card Team|Trading Card Admins"
)
USER <-
topic %>%
rvest::html_nodes(".profile-username") %>%
dplyr::nth(1) %>%
rvest::html_text() %>%
stringr::str_split("\n") %>%
unlist() %>%
## Usually the user name starts with a \n so the second cell holds the user info
dplyr::nth(2) %>%
stringr::str_remove(
pattern = userTags
)
USER
USERLINK <-
topic %>%
rvest::html_nodes(".profile-username") %>%
dplyr::nth(1) %>%
rvest::html_nodes(xpath = "./a") %>%
rvest::html_attr("href")
USERLINK
USERLINK <-
topic %>%
rvest::html_nodes(".profile-username") %>%
dplyr::nth(1) %>%
rvest::html_nodes(xpath = "./a") %>%
rvest::html_attr("href")
## GitHub raw url
raw <- "https://raw.githubusercontent.com/canadice/shl/main/"
teamInfo <-
read.csv2(
paste(
raw,
"csv/team_information.csv",
sep = "")
)
View(teamInfo)
usethis::use_data(teamInfo, internal = TRUE)
usethis::use_data(teamInfo, internal = TRUE, overwrite = TRUE)
